Ejercicio 4:

train: all - Outlander01.txt
test: Outlander01.txt

modeladdone1gram
Log probability: -3853485.0819229544
Cross entropy: 9.362390624509112
Perplexity: 658.20383611275

sobre el mismo corpus de entrenamiento
Log probability: -31703639.881051958
Cross entropy: 9.271691331130986
Perplexity: 618.0978048404776

modeladdone2gram
Log probability: -4028672.095467275
Cross entropy: 9.788023322774192
Perplexity: 884.0739999067799

modeladdone3gram
Log probability: -5234911.688916774
Cross entropy: 12.718691541421538
Perplexity: 6740.7412954589745

modeladdone4gram
Log probability: -5728369.843379073
Cross entropy: 13.91759276997384
Perplexity: 15474.366948279174

sobre el mismo corpus de entrenamiento
Log probability: -44854392.5005444
Cross entropy: 13.117613109118027
Perplexity: 8887.815228771982

